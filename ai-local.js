/* IA locale (WebLLM) â€” rÃ©Ã©criture â€œstyle antenneâ€ sans clÃ©
   TolÃ©rant aux blocages CDN/Worker : essaie CDN puis bascule en local.
*/
(() => {
  const STATUS = () => document.getElementById('iaLocalStatus');
  const OUT = () => document.getElementById('resultat');
  const BTN = () => document.getElementById('btnRewriteLocal');

  let webllmClient = null;
  let webllmReady = false;

  // --- chemins ---
  const CDN_SCRIPT   = "https://unpkg.com/@mlc-ai/web-llm/dist/web-llm.min.js";
  const CDN_WORKER   = "https://unpkg.com/@mlc-ai/web-llm/dist/worker.js";
  const LOCAL_SCRIPT = "/vendor/web-llm/web-llm.min.js";
  const LOCAL_WORKER = "/vendor/web-llm/worker.js";

  // ModÃ¨le compact
  const MODEL_NAME   = "Phi-3-mini-4k-instruct-q4f16_1-MLC";

  const text = (el, t) => { if (el) el.textContent = t; };
  const log  = (...a) => console.log("[AI-LOCAL]", ...a);

  // Affiche un petit diagnostic utile
  function printEnvDiag() {
    const diag = [
      `webllm:${!!window.webllm}`,
      `Worker:${!!window.Worker}`,
      `GPU:${!!navigator.gpu}`,
      `Prot:${location.protocol}`,
      `COI:${self.crossOriginIsolated === true}`
    ].join(" | ");
    log(diag);
    text(STATUS(), `Diagnostic: ${diag}`);
  }

  // Injecte un script <script src=...> et rÃ©sout quand chargÃ©
  function injectScript(src) {
    return new Promise((resolve, reject) => {
      const s = document.createElement('script');
      s.src = src;
      s.defer = true;
      s.onload = () => resolve(true);
      s.onerror = () => reject(new Error("Ã©chec chargement " + src));
      document.head.appendChild(s);
    });
  }

  // Charge web-llm soit via CDN, soit via local
  async function ensureWebLLMScript() {
    if (window.webllm) return "present";
    // 1) tente CDN
    try {
      await injectScript(CDN_SCRIPT);
      log("CDN web-llm.min.js OK");
      return "cdn";
    } catch (e) {
      log("CDN web-llm.min.js KO", e);
      // 2) fallback local
      await injectScript(LOCAL_SCRIPT);
      log("LOCAL web-llm.min.js OK");
      return "local";
    }
  }

  // Essaie dâ€™instancier un Worker module
  function tryCreateWorker(url) {
    try { return new Worker(url, { type: "module" }); }
    catch (e) { log("Worker fail", url, e); return null; }
  }

  async function ensureWebLLM() {
    if (webllmReady) return;

    printEnvDiag();
    if (!window.Worker) throw new Error("Les Web Workers sont dÃ©sactivÃ©s.");

    const origin = await ensureWebLLMScript(); // "cdn" | "local" | "present"

    text(STATUS(), "â³ Initialisation de lâ€™IA localeâ€¦ (tÃ©lÃ©chargement du modÃ¨le)");

    // on privilÃ©gie le worker du mÃªme â€œorigineâ€ que la lib
    let worker =
      (origin === "cdn")   ? tryCreateWorker(CDN_WORKER)   :
      (origin === "local") ? tryCreateWorker(LOCAL_WORKER) :
                              tryCreateWorker(CDN_WORKER) || tryCreateWorker(LOCAL_WORKER);

    if (!worker) {
      // dernier essai : lâ€™autre origine
      worker = tryCreateWorker(CDN_WORKER) || tryCreateWorker(LOCAL_WORKER);
    }
    if (!worker) {
      throw new Error("Impossible de crÃ©er un Worker (CDN & local). VÃ©rifie /vendor/web-llm/worker.js et les extensions de sÃ©curitÃ©.");
    }

    // wasmProxy => autorise le fallback CPU/WASM (plus lent), pas besoin absolu de WebGPU.
    webllmClient = new webllm.ChatWorkerClient(worker, { wasmProxy: true });

    webllmClient.setInitProgressCallback((p) => {
      const pct = p?.progress != null ? Math.round(p.progress * 100) : null;
      text(STATUS(), pct != null ? `â¬‡ï¸ TÃ©lÃ©chargement du modÃ¨le (${pct}%)â€¦` : (p?.text || "PrÃ©paration du modÃ¨leâ€¦"));
    });

    try {
      await webllmClient.reload({ model: MODEL_NAME });
    } catch (e) {
      throw new Error("Ã‰chec chargement modÃ¨le (rÃ©seau/CORS/navigateur). DÃ©tail: " + (e?.message || e));
    }

    webllmReady = true;
    text(STATUS(), "âœ… IA locale prÃªte.");
    setTimeout(() => text(STATUS(), ""), 1500);
  }

  function buildLocalInstruction() {
    const style = document.getElementById('iaStyle')?.value || 'journalistique';
    const longueur = document.getElementById('iaLongueur')?.value || 'conserve';
    const addr = document.getElementById('iaTutoiement')?.value || 'neutre';

    const styleMap = {
      journalistique: "Ton journalistique radio, naturel, fluide, transitions orales.",
      dynamique: "Ton dynamique et Ã©nergique, phrases courtes, transitions rythmÃ©es.",
      sobre: "Ton sobre et clair, informatif, enchaÃ®nements posÃ©s.",
      pedagogique: "Ton pÃ©dagogique, clair, vulgarisation lÃ©gÃ¨re, transitions explicatives."
    };
    const lenMap = {
      conserve: "Conserver sensiblement la longueur.",
      condense: "Condense environ 25% sans perdre les infos clÃ©s.",
      developpe: "DÃ©veloppe environ 25% avec explications lÃ©gÃ¨res."
    };
    const addrMap = {
      neutre: "Adresse neutre (sans tutoiement/vouvoiement marquÃ©).",
      vous: "Adresse l'auditoire au 'vous'.",
      tu: "Adresse l'auditoire au 'tu'."
    };

    return [
      styleMap[style], lenMap[longueur], addrMap[addr],
      "Respecte strictement les faits. Ã‰cris pour lâ€™oral antenne : connecteurs (dâ€™abord, ensuite, enfin, en rÃ©sumÃ©), phrases naturelles.",
      "Ã‰vite les puces, pas de jargon. Ajoute un lancement simple et une chute courte si pertinent. Nâ€™invente aucune info."
    ].join(" ");
  }

  async function rewriteWithLocalAI() {
    const out = OUT();
    const status = STATUS();
    const btn = BTN();
    const source = (out?.textContent || '').trim();

    if (!source) { alert("Compile dâ€™abord un texte (ou insÃ¨re depuis GuidÃ©/Interview)."); return; }

    btn.disabled = true;
    try {
      await ensureWebLLM();
      text(status, "ðŸ§  RÃ©Ã©criture locale en coursâ€¦");

      const messages = [
        { role: "system", content: "Tu es un rÃ©dacteur radio francophone. Tu rends un texte brut fluide et naturel Ã  dire Ã  lâ€™antenne, sans inventer dâ€™informations." },
        { role: "user", content: `Consignes: ${buildLocalInstruction()}\n\nTexte Ã  rÃ©Ã©crire:\n${source}` }
      ];

      const result = await webllmClient.chatCompletion({ messages, temperature: 0.7, max_tokens: 1000, stream: false });
      const rewritten = result?.choices?.[0]?.message?.content?.trim();
      if (!rewritten) throw new Error("RÃ©ponse vide.");

      out.textContent = rewritten;
      localStorage.setItem("resultat", rewritten);
      text(status, "âœ… RÃ©Ã©criture terminÃ©e (IA locale).");
      setTimeout(() => text(status, ""), 3000);
    } catch (e) {
      console.error(e);
      text(STATUS(), "âŒ Erreur IA locale : " + (e?.message || e));
      alert("Erreur IA locale.\nâ€¢ VÃ©rifie /vendor/web-llm/web-llm.min.js et /vendor/web-llm/worker.js\nâ€¢ Essaie Chrome/Edge rÃ©cents\nâ€¢ Ouvre via http://localhost (pas file://)\nâ€¢ DÃ©sactive temporairement les bloqueurs.");
    } finally {
      btn.disabled = false;
    }
  }

  document.addEventListener('DOMContentLoaded', () => {
    const btn = BTN();
    if (btn) btn.addEventListener('click', rewriteWithLocalAI);
  });
})();
